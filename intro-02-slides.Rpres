Reproducible Science Workshop - Intro II
========================================================
font-family: 'Helvetica'
date: 'enter date'


[earlier material has already been moved to intro-02-slides,
will delete this file entirely when all has been moved there]

Revisit Exercise 1 
========================================================

* Open `intro-01-template.Rmd` 
* Click on *Knit HTML* to compile the document


Goals of the next exercise
========================================================

* Demonstrate "good practice" for organizing data files and analysis 
documents (RMarkdown)
* How to read data from a file
* How to combine data from multiple data frames
* How to subset data
* How to make simple plots in ggplot

**NOT** about understanding all the R commands, but **rather** getting the big 
picture of how using R in this way facilitates reproducible analyses


Exercise 2: Extending your analysis
========================================================

1. Append the new data `gapminder-7080.csv` and `gapminder-90plus.csv` to your 
existing data set. <br>*Be careful* as you do so, as the ordering of columns 
in the data set may not match between the different CSV files!

2. Create line plots of life expectancy over time for Canada, Mexico, and the 
United States that run from 1952 to 2007.<br>
*Stretch goal:* In the same plot, add similar line plots for Cambodia, China, and 
Japan and Uganda, Egypt, and South Africa.

3. Create a scatter plot depicting GDP vs. life expectancy of countries in Europe 
for 2007. <br>
*Stretch goal:* In the same plot, add another scatter of points for Asia, Africa, 
and the Americas, coloring the countries from each region (continent) with the 
same color.


Exercise 2: Resources
========================================================

* Open `intro-02-template.Rmd` 
* Click on *Knit HTML* to compile the document


Exercise 2: Take aways
========================================================

* The analysis is self-documenting
* It's easy to extend or refine analyses by copying and modifying code blocks
* The results of the analysis can be disseminated by sending Markdown and 
providing data sources, or just simply providing the generated HTML of just 
a summary of the analysis is needed


Reproducibility checklist
========================================================

* Serves as a tool to help you think about the reproducibility of your data 
analysis
* Many of the questions can be thought of as having a yes/no answer
* A better approach would be to see the questions as being open ended with 
the real question being, "What can I do to improve the status of my project 
on this bullet point?"
* With that in mind, you'll never get 100% of the bullets right for your project, 
but you'll always be improving


Reproducibility checklist: Documentation (1/2)
========================================================

* Is there a README file that indicates the purpose of the project, who to contact 
with questions, a map of the directory structure, and a description of what software 
and hardware is needed to reproduce your workflow?
* Are there README files in each folder describing the contents of the folder, 
how they were acquired/generated?
* Is there a CITATION file that tells users how to site the project, data, and code?
* Are there instructions on how to obtain the raw data and citations for those data?
* Is there a list of dependencies with the exact version number of every external application used in the process?
* Do you indicate dates that websites were accessed to obtain data?


Reproducibility checklist: Documentation (2/2)
========================================================
* Are there appropriate LICENSE files that specify the license under which you're
distributing your content, data, and code? Have you edited them to include info 
pertinent to your project?
* Have you noted the license(s) for others peoples' content, data, and code used 
in your analysis?
* For analyses that utilize a random number generator, have you noted the underlying 
random seed(s)? Do you state the other seeds that you have tested the results with?
* Is your code well documented?
* Do you use a self-commenting coding practice?
* Do each of your scripts have a header indicating the inputs, outputs, and dependencies?
* Is it documented how files relate to each other?